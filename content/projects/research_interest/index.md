---
title: AI-Accelerated News Media
summary:
tags:
date: "2021-05-01T00:00:00Z"

---

My research interests lie in the realization of AI-accelerated news media. This involves creating new experiences and improving operational efficiency in all stages of news production.
In particular, we focus on exploring opportunities and challenges for pre-trained models in news media.

### Challenges in Practice

<iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/3813f4b9e4af4f328a96f2fdb9484bd8" title="日本語新聞記事を用いた大規模言語モデルの暗記定量化 / LLMC2025" allowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" data-ratio="1.7777777777777777"></iframe>

- Monitoring time-series performance degradation ([AACL-IJCNLP 2022](https://aclanthology.org/2022.aacl-main.17/) & [IC2S2 2023](https://upura.github.io/pdf/ic2s2_2023_semantic_shift.pdf) => [Journal of Natural Language Processing](https://doi.org/10.5715/jnlp.31.1563))
- Training data extraction
    - Survey paper ([ACL 2023 Workshop](https://aclanthology.org/2023.trustnlp-1.23/))
    - Experiments on Japanese newspaper ([INLG 2024](https://aclanthology.org/2024.inlg-main.14/), [ACL 2025 Workshop](https://aclanthology.org/2025.l2m2-1.8/))
- Hallucination analysis on domain-specific PLMs ([Journal of Natural Language Processing](https://doi.org/10.5715/jnlp.31.1717))

### Building and Applying Pre-trained Models

<iframe class="speakerdeck-iframe" frameborder="0" src="https://speakerdeck.com/player/7c1fff569f0449c6bd056f0ec45f57e1" title="ニュースメディアにおける事前学習済みモデルの可能性と課題 / IBIS2024" allowfullscreen="true" style="border: 0px; background: padding-box padding-box rgba(0, 0, 0, 0.1); margin: 0px; padding: 0px; border-radius: 6px; box-shadow: rgba(0, 0, 0, 0.2) 0px 5px 40px; width: 100%; height: auto; aspect-ratio: 560 / 315;" data-ratio="1.7777777777777777"></iframe>

- Building domain-specific large language models ([Press release](https://www.nikkei.co.jp/nikkeiinfo/en/news/press/release_en_20240424_01.pdf) & [Journal of Natural Language Processing](https://doi.org/10.5715/jnlp.31.1717))
- PLMs for news industry:
    - Crossword puzzle generation ([CIKM 2023](https://dl.acm.org/doi/10.1145/3583780.3615151))
    - Reading time estimation ([BigData 2022 Industrial & Government Track](https://ieeexplore.ieee.org/document/10020618))
    - Multilingual news similarity scoring ([NAACL 2022 Workshop](https://aclanthology.org/2022.semeval-1.171/))
    - Next Item Recommendation ([WSDM 2021 Workshop](https://ceur-ws.org/Vol-2855/challenge_short_7.pdf))

## Reference

You can see [Publications](https://upura.github.io/projects/publications/) for more details.
